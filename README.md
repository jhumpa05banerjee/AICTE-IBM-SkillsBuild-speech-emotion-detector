# AICTE-IBM-SkillsBuild-speech-emotion-detector
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
 
</head>
<body>

<h1>ğŸ¤ Speech Emotion Detection Web Application</h1>

<p>
A <b>full-stack AI-based web application</b> that analyzes human speech and detects emotional states such as 
<b>Calm, Happy, Disgust, and Fearful</b> using <b>machine learning and audio signal processing</b>. 
The system provides <b>real-time visual emotion analysis</b> using interactive charts and UI components.
</p>

<hr />

<h2>ğŸ“Œ Features</h2>
<ul>
  <li>ğŸ§ Upload or record audio input</li>
  <li>ğŸ§  Extract speech features and classify emotions</li>
  <li>ğŸ“Š Display emotion probabilities using charts</li>
  <li>âš¡ Fast, modern, and responsive web interface</li>
  <li>ğŸ¤– Machine Learningâ€“powered emotion prediction</li>
</ul>

<hr />

<h2>ğŸ›  Technology Stack</h2>

<h3>Frontend:</h3>
<ul>
  <li>Next.js</li>
  <li>React.js</li>
  <li>TypeScript</li>
  <li>Tailwind CSS</li>
  <li>Recharts</li>
</ul>

<h3>Backend & AI:</h3>
<ul>
  <li>Python</li>
  <li>Librosa (audio processing)</li>
  <li>NumPy</li>
  <li>Machine Learning Model (Speech Emotion Recognition)</li>
</ul>

<h3>Tools:</h3>
<ul>
  <li>Node.js</li>
  <li>pnpm (package manager)</li>
  <li>Python Virtual Environment (venv)</li>
</ul>

<hr />

<h2>âš™ Installation & Setup Instructions</h2>
<p>Follow these steps carefully to run the project locally.</p>

<h3>1ï¸âƒ£ Unzip the Project File</h3>
<pre><code>unzip speech-emotion-detector.zip
cd speech-emotion-detector</code></pre>

<h3>2ï¸âƒ£ Create Python Virtual Environment</h3>
<pre><code>python -m venv venv</code></pre>

<p>Activate it:</p>

<b>Windows:</b>
<pre><code>venv\Scripts\activate</code></pre>

<b>Mac / Linux:</b>
<pre><code>source venv/bin/activate</code></pre>

<h3>3ï¸âƒ£ Install Python Dependencies</h3>
<pre><code>pip install -r requirements.txt</code></pre>

<h3>4ï¸âƒ£ Install Frontend Dependencies</h3>
<pre><code>pnpm install</code></pre>

<h3>5ï¸âƒ£ Build the Project (Production Mode)</h3>
<pre><code>pnpm build</code></pre>

<h3>6ï¸âƒ£ Start the Production Server</h3>
<pre><code>pnpm start</code></pre>

<h3>7ï¸âƒ£ Open in Browser</h3>
<pre><code>http://localhost:3000</code></pre>

<hr />

<h2>ğŸš€ How the System Works</h2>

<pre><code>Audio Input
     â†“
Audio Preprocessing
     â†“
Feature Extraction
     â†“
Machine Learning Model
     â†“
Emotion Classification
     â†“
Graphical Visualization</code></pre>

<hr />

<h2>ğŸ“Š Output</h2>
<p>
The system predicts emotions such as:
</p>
<ul>
  <li>Calm</li>
  <li>Happy</li>
  <li>Disgust</li>
  <li>Fearful</li>
</ul>

<p>
and displays <b>probability percentages</b> using <b>interactive charts and tooltips</b>.
</p>

<hr />

<h2>ğŸ¯ Application Areas</h2>
<ul>
  <li>Human-computer interaction</li>
  <li>Mental health monitoring</li>
  <li>Emotion-aware AI systems</li>
  <li>Call center emotion analysis</li>
  <li>Smart assistants</li>
</ul>

<hr />

<h2>ğŸ‘¨â€ğŸ’» Developed By</h2>
<p>
<b>Jhumpa Banerjee</b><br/>
Department of <b>Computer Science and Engineering</b><br/>
Institution: <b>Jaypee Institute of Information Technology</b>
</p>

<hr />

<h2>ğŸ“œ License</h2>
<p>
This project is developed for <b>academic and educational purposes only</b>.
</p>

</body>
</html>
